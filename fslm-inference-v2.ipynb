{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/pavanbagli/fslm-inference-v2?scriptVersionId=177059520\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<a name='1'></a>\n## 1 - Install and Imports","metadata":{"id":"5ZXjh6D9nOUX"}},{"cell_type":"code","source":"import os\nimport sys","metadata":{"id":"8WpB3YxZITwK","execution":{"iopub.status.busy":"2022-06-28T12:55:41.168714Z","iopub.execute_input":"2022-06-28T12:55:41.169255Z","iopub.status.idle":"2022-06-28T12:55:41.173177Z","shell.execute_reply.started":"2022-06-28T12:55:41.169195Z","shell.execute_reply":"2022-06-28T12:55:41.172232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#os.system('pip3 install --no-index --find-links ../input/httplib2v17 httplib2==0.17.4')\n#os.system('pip3 install -U --no-index --find-links ../input/pyparsing247 pyparsing==2.4.7')\n#os.system('pip3 install -U --no-index --find-links ../input/grpcio grpcio')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import httplib2\nimport pyparsing\nimport apache_beam as beam\n\nprint('httplib2 version: {}'.format(httplib2.__version__))\nprint('pyparsing version: {}'.format(pyparsing.__version__))\nprint('beam version: {}'.format(beam.__version__))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:55:43.386824Z","iopub.execute_input":"2022-06-28T12:55:43.38781Z","iopub.status.idle":"2022-06-28T12:55:43.86032Z","shell.execute_reply.started":"2022-06-28T12:55:43.387767Z","shell.execute_reply":"2022-06-28T12:55:43.859296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#os.system('pip3 install --no-index --find-links ../input/tfx1800/tfx1800wheel/kaggle/working tfx==1.8.0')\n#os.system('pip3 install --no-index --find-links ../input/tensorflowtext2600/kaggle/working tensorflow-text==2.6.0')\nos.system('pip3 install --no-index --find-links ../input/tftext/tensorflowtext2600wheel/kaggle/working tensorflow-text==2.6.0')\n#!pip3 install --no-index --find-links ../input/tftext/tensorflowtext2600wheel/kaggle/working tensorflow-text==2.6.0\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv\nimport pandas as pd\nimport numpy as np\nimport argparse\nfrom typing import Dict, Text, Any, Tuple, List\nfrom apache_beam.options.pipeline_options import PipelineOptions\n\nimport tensorflow as tf\nimport tensorflow_text\nfrom tensorflow import keras\nfrom tensorflow.core.example import example_pb2\n\nimport tfx_bsl\nfrom tfx_bsl.public.beam import RunInference\nfrom tfx_bsl.public import tfxio\nfrom tfx_bsl.public.proto import model_spec_pb2\n\ntf.get_logger().setLevel('ERROR')\n\nprint('TensorFlow version: {}'.format(tf.__version__))\nprint('Beam version: {}'.format(beam.__version__))","metadata":{"id":"TK6SyLhQP_s5","outputId":"a8ee43fd-9479-4da2-a76e-56436d23517b","execution":{"iopub.status.busy":"2022-06-28T12:55:47.240176Z","iopub.execute_input":"2022-06-28T12:55:47.241323Z","iopub.status.idle":"2022-06-28T12:55:50.060817Z","shell.execute_reply.started":"2022-06-28T12:55:47.241285Z","shell.execute_reply":"2022-06-28T12:55:50.059768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_DIR = '../input/fslm-basemodel-v2/model/6/Format-Serving'\n\nINPUT_SOURCE_DIR = '../input/foursquare-location-matching'\nINPUT_SOURCE_TEST_DATA = f'{INPUT_SOURCE_DIR}/test.csv'\nINPUT_SOURCE_PAIRS_DATA = f'{INPUT_SOURCE_DIR}/pairs.csv'\n\nVALIDATE_DIR = './'\nVALIDATE_DATA = f'{VALIDATE_DIR}/validate.csv'\n\nSERVING_DIR = './serving'\nSERVING_DATA = f'{SERVING_DIR}/serve.csv'\n\nTFRECORD_DIR = './tfrecords' \nOUTPUT_RESULTS_DIR = './'\nOUTPUT_RESULTS = f'{OUTPUT_RESULTS_DIR}/output-'\n\n!mkdir -p {VALIDATE_DIR}\n!mkdir -p {SERVING_DIR}\n!mkdir -p {TFRECORD_DIR}\n","metadata":{"id":"TBJqC6-HfymZ","execution":{"iopub.status.busy":"2022-06-28T12:55:56.433564Z","iopub.execute_input":"2022-06-28T12:55:56.433932Z","iopub.status.idle":"2022-06-28T12:55:58.421856Z","shell.execute_reply.started":"2022-06-28T12:55:56.433902Z","shell.execute_reply":"2022-06-28T12:55:58.420589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name='2'></a>\n## 2 - Load Saved Model","metadata":{"id":"bsHcencfobKL"}},{"cell_type":"code","source":"model = tf.keras.models.load_model(MODEL_DIR)\n#model.summary()","metadata":{"id":"vXTh751Hb_MO","outputId":"09a5d08a-050a-4634-e893-adab57b4ecb7","execution":{"iopub.status.busy":"2022-06-28T12:56:05.961926Z","iopub.execute_input":"2022-06-28T12:56:05.962382Z","iopub.status.idle":"2022-06-28T12:56:22.944391Z","shell.execute_reply.started":"2022-06-28T12:56:05.962339Z","shell.execute_reply":"2022-06-28T12:56:22.943286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.get_layer('transform_features_layer') is model.tft_layer","metadata":{"id":"03bvyxkj-vnS","outputId":"8d97797f-5384-46fd-8d1b-1e4787b9e976","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name='3'></a>\n## 3 - Load Data for Inference","metadata":{"id":"nhiXA2xTZX2q"}},{"cell_type":"code","source":"def generate_pairs(df_1, df_2):\n  pairs_temp=df_1.merge(df_2, how='cross', suffixes=('_1', '_2'))\n  pairs_temp = pairs_temp[pairs_temp['id_1'] != pairs_temp['id_2']]\n  #combine address columns : address_1, city_1, state_1, zip_1 to full_address_1\n  pairs_temp['full_address_1'] = pairs_temp['address_1'].map(str) + \" \" + pairs_temp['city_1'].map(str) + \" \" + pairs_temp['state_1'].map(str) + \" \" + pairs_temp['zip_1'].map(str) + \" Phone: \" + pairs_temp['phone_1'].map(str)\n  pairs_temp['full_address_2'] = pairs_temp['address_2'].map(str) + \" \" + pairs_temp['city_2'].map(str) + \" \" + pairs_temp['state_2'].map(str) + \" \" + pairs_temp['zip_2'].map(str) + \" Phone: \" + pairs_temp['phone_2'].map(str)\n  pairs_temp = pairs_temp.drop(columns=['address_1','city_1','state_1','zip_1', 'phone_1', 'address_2','city_2','state_2','zip_2', 'phone_2'], axis=1)\n  pairs_temp.to_csv(SERVING_DATA, index=False)\n  del pairs_temp","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:56:23.801135Z","iopub.execute_input":"2022-06-28T12:56:23.801813Z","iopub.status.idle":"2022-06-28T12:56:23.812459Z","shell.execute_reply.started":"2022-06-28T12:56:23.801773Z","shell.execute_reply":"2022-06-28T12:56:23.810938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#def csv_to_tfrecord(schema, csv_file, tfrecord_file):\ndef csv_to_tfrecord(csv_file, tfrecord_file):\n  ''' Converts a csv file into a tfrecord\n  Args:\n    csv_file (string) - file to convert to tfrecord\n    tfrecord_file (string) - filename of tfrecord to create\n\n  Returns:\n    filename of tfrecord\n  '''\n  float_features = ['latitude_1','latitude_2','longitude_1','longitude_2']\n  byte_features = ['categories_1','categories_2','country_1','country_2','full_address_1','full_address_2','id_1','id_2','name_1','name_2','url_1','url_2']\n\n  # Open CSV file for reading. Each row is mapped as a dictionary.\n  reader = csv.DictReader(open(csv_file, 'r'))\n  \n  # Initialize TF examples list\n  examples = []\n\n  # For each row in CSV, create a TF Example based on\n  # the Schema and append to the list\n  for line in reader:\n    # Intialize example\n    example = example_pb2.Example()\n\n    for feature in float_features:\n      key=feature\n      example.features.feature[key].float_list.value[:] = (\n              [float(line[key])] if len(line[key]) > 0 else [])\n\n    for feature in byte_features:\n      key=feature\n      example.features.feature[key].bytes_list.value[:] = (\n              [line[key].encode('utf8')] if len(line[key]) > 0 else [])\n\n    # Append to the list\n    examples.append(example)\n\n  # Write examples to tfrecord file\n  with tf.io.TFRecordWriter(tfrecord_file) as writer:\n    for example in examples:\n      writer.write(example.SerializeToString())\n  \n  return tfrecord_file","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:56:29.729112Z","iopub.execute_input":"2022-06-28T12:56:29.729669Z","iopub.status.idle":"2022-06-28T12:56:29.739537Z","shell.execute_reply.started":"2022-06-28T12:56:29.729634Z","shell.execute_reply":"2022-06-28T12:56:29.738283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ToCsvFn(beam.DoFn):\n    def process(self, element):\n        # This parses out the example features that were passed in during prediction\n        example = tf.io.parse_single_example(tf.make_ndarray(element.predict_log.request.inputs['examples'])[0], features)\n        example_values = [ v.numpy() for v in example.values() ]\n        example_values = [ x.decode('utf-8') if isinstance(x, bytes) else x for x in example_values ]\n        predictions = tf.make_ndarray(element.predict_log.response.outputs['outputs'])\n        full_result = example_values + list(predictions[0])\n        yield ','.join([ str(f) for f in full_result])","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:56:38.242994Z","iopub.execute_input":"2022-06-28T12:56:38.243384Z","iopub.status.idle":"2022-06-28T12:56:38.252213Z","shell.execute_reply.started":"2022-06-28T12:56:38.24335Z","shell.execute_reply":"2022-06-28T12:56:38.251289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predictions():\n  pipeline = beam.Pipeline()\n  tfexample_beam_record = tfx_bsl.public.tfxio.TFExampleRecord(file_pattern='./tfrecords/*.tfrecord')\n\n  with pipeline as p:\n    _ = (p | tfexample_beam_record.RawRecordBeamSource()\n            | RunInference(\n                model_spec_pb2.InferenceSpecType(\n                    saved_model_spec=model_spec_pb2.SavedModelSpec(model_path=MODEL_DIR)))\n            | beam.ParDo(ToCsvFn())\n            | beam.io.WriteToText(OUTPUT_RESULTS,header='id_1,id_2,match')\n            | beam.Map(print)\n        )\n","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:56:41.104455Z","iopub.execute_input":"2022-06-28T12:56:41.104813Z","iopub.status.idle":"2022-06-28T12:56:41.111503Z","shell.execute_reply.started":"2022-06-28T12:56:41.10478Z","shell.execute_reply":"2022-06-28T12:56:41.110482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_output_dict(rows):\n    output = {}\n    match_ids = []\n    row_id_prev = 'Null'\n    for row in rows:\n        if row_id_prev == 'Null':\n            row_id_prev = row[0]\n            match_ids.append(row[0])\n            \n        \n        if row[0] == row_id_prev:\n            \n            if row[2] > 0.5:\n                match_ids.append(row[1])\n        \n        else:\n            \n            output[row_id_prev] = ' '.join(match_ids)\n            match_ids = []\n            match_ids.append(row[0])\n            if row[2] > 0.5:\n                match_ids.append(row[1])\n        \n        row_id_prev = row[0]\n        \n    output[row_id_prev] = ' '.join(match_ids)\n    return output","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:07:18.463338Z","iopub.execute_input":"2022-06-28T13:07:18.464105Z","iopub.status.idle":"2022-06-28T13:07:18.473426Z","shell.execute_reply.started":"2022-06-28T13:07:18.464068Z","shell.execute_reply":"2022-06-28T13:07:18.472312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def write_csv_file(output_dir, output_dict):\n    with open(f'{OUTPUT_RESULTS_DIR}/submission.csv', 'a') as csv_file:\n        writer = csv.writer(csv_file)\n        for key, value in output_dict.items():\n            writer.writerow([key, value])","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:56:52.53598Z","iopub.execute_input":"2022-06-28T12:56:52.536572Z","iopub.status.idle":"2022-06-28T12:56:52.543295Z","shell.execute_reply.started":"2022-06-28T12:56:52.536529Z","shell.execute_reply":"2022-06-28T12:56:52.542401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(f'{OUTPUT_RESULTS_DIR}/submission.csv', 'w') as csv_file:\n    writer = csv.writer(csv_file)\n    writer.writerow(['id', 'matches'])","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:56:55.254818Z","iopub.execute_input":"2022-06-28T12:56:55.255244Z","iopub.status.idle":"2022-06-28T12:56:55.261265Z","shell.execute_reply.started":"2022-06-28T12:56:55.255193Z","shell.execute_reply":"2022-06-28T12:56:55.260151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ninf_df = pd.read_csv(INPUT_SOURCE_TEST_DATA)\ninf_df.drop_duplicates(inplace=True)\nfeatures = {\n    'id_1': tf.io.FixedLenFeature([], tf.string),\n    'id_2': tf.io.FixedLenFeature([], tf.string),\n     }","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:57:05.326175Z","iopub.execute_input":"2022-06-28T12:57:05.326804Z","iopub.status.idle":"2022-06-28T12:57:05.351894Z","shell.execute_reply.started":"2022-06-28T12:57:05.326766Z","shell.execute_reply":"2022-06-28T12:57:05.351029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0,inf_df.shape[0],10):\n    \n    generate_pairs(inf_df[i:i+10], inf_df)\n\n  # Create list of tfrecord files\n  #tfrecord_files = [csv_to_tfrecord(f'{SERVING_DIR}/{name}', f\"{TFRECORD_DIR}/{name + str(i).replace('csv','tfrecord')}\") \n    tfrecord_files = [csv_to_tfrecord(f'{SERVING_DIR}/{name}', f\"{TFRECORD_DIR}/{str(i) + '.tfrecord'}\") \n        for name in os.listdir(SERVING_DIR)]\n\n    predictions()\n    \n    pred_df = pd.read_csv('./output--00000-of-00001')\n    pred_df = pred_df.sort_values(['id_1', 'id_2', 'match'])\n    rows = pred_df.values\n    output_dict = create_output_dict(rows)\n    write_csv_file(OUTPUT_RESULTS_DIR, output_dict)\n\n    del tfrecord_files\n    del pred_df\n    del rows\n    del output_dict\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:13:26.391266Z","iopub.execute_input":"2022-06-28T13:13:26.391653Z","iopub.status.idle":"2022-06-28T13:15:49.802822Z","shell.execute_reply.started":"2022-06-28T13:13:26.391621Z","shell.execute_reply":"2022-06-28T13:15:49.801881Z"},"trusted":true},"execution_count":null,"outputs":[]}]}