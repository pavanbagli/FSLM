{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":35476,"databundleVersionId":3515015,"sourceType":"competition"}],"dockerImageVersionId":30204,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a name='1'></a>\n## 1 - Install and Imports","metadata":{"id":"5ZXjh6D9nOUX"}},{"cell_type":"code","source":"!pip install -U tfx \n!pip3 install tensorflow_text>=2.0.0rc0  ","metadata":{"id":"8WpB3YxZITwK","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nimport pandas as pd\nimport tempfile\nimport numpy as np\nimport pprint\nimport argparse\nfrom typing import Dict, Text, Any, Tuple, List\n\nimport tensorflow as tf\n\nimport tensorflow_model_analysis as tfma\nimport tensorflow_data_validation as tfdv\nimport tensorflow_transform as tft\nimport apache_beam\n\nfrom tensorflow import keras\nfrom tfx.components import CsvExampleGen\nfrom tfx.components import ExampleValidator\nfrom tfx.components import SchemaGen\nfrom tfx.components import StatisticsGen\nfrom tfx.components import Transform\nfrom tfx.components import Tuner\nfrom tfx.components import Trainer\nfrom tfx.components import BulkInferrer\nfrom tfx.types import standard_artifacts\nfrom tfx import v1 as tfx\nfrom tfx import types\nfrom tfx.components.bulk_inferrer import prediction_to_example_utils\nfrom tfx.components.util import model_utils\nfrom tfx.proto import bulk_inferrer_pb2\nfrom tfx.proto import trainer_pb2\nfrom tfx.proto import example_gen_pb2\nfrom tfx.types import artifact_utils\nfrom tfx.utils import io_utils\nfrom tfx.utils import path_utils\nfrom tfx.dsl.components.base import base_executor\n\nfrom tfx_bsl.public.proto import model_spec_pb2\nfrom tfx_bsl.public.beam import RunInference\nfrom tfx_bsl.public import tfxio\n\nfrom tensorflow.python.lib.io import file_io\nfrom tensorflow_metadata.proto.v0 import schema_pb2\nfrom tensorflow_serving.apis import prediction_log_pb2\nfrom tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n%load_ext tfx.orchestration.experimental.interactive.notebook_extensions.skip\n\nfrom google.protobuf import json_format\nfrom google.protobuf import text_format\nfrom google.protobuf.json_format import MessageToDict\n\nimport apache_beam as beam\nfrom apache_beam.options.pipeline_options import PipelineOptions\n\ntf.get_logger().setLevel('ERROR')\npp = pprint.PrettyPrinter()\n\n# Display versions of TF and TFX related packages\nprint('TensorFlow version: {}'.format(tf.__version__))\nprint('TFX version: {}'.format(tfx.__version__))\nprint('TensorFlow Data Validation version: {}'.format(tfdv.__version__))\nprint('TensorFlow Transform version: {}'.format(tft.__version__))","metadata":{"id":"TK6SyLhQP_s5","outputId":"0a12bcbf-5d1c-40ee-b816-821af43c5fec","execution":{"iopub.status.busy":"2022-07-06T09:15:09.881561Z","iopub.execute_input":"2022-07-06T09:15:09.882257Z","iopub.status.idle":"2022-07-06T09:15:17.243018Z","shell.execute_reply.started":"2022-07-06T09:15:09.882169Z","shell.execute_reply":"2022-07-06T09:15:17.241921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name='2'></a>\n## 2 - Load the dataset","metadata":{"id":"bsHcencfobKL"}},{"cell_type":"code","source":"# Declare paths to the data\n\nINPUT_SOURCE_DIR = '../input/foursquare-location-matching'\nINPUT_SOURCE_PAIRS_DATA = f'{INPUT_SOURCE_DIR}/pairs.csv'\nINPUT_SOURCE_TRAIN_DATA = f'{INPUT_SOURCE_DIR}/train.csv'\nINPUT_SOURCE_TEST_DATA = f'{INPUT_SOURCE_DIR}/test.csv'\n\nPIPELINE_DIR = './pipeline'\n\nTRAINING_DATA_DIR = './training_data'\nTRAINING_DATA = f'{TRAINING_DATA_DIR}/dataset.csv'\n\nSERVING_MODEL_DIR = './serving_model'\nSERVING_DATA_DIR = './serving_data'\nSERVING_DATA = f'{SERVING_DATA_DIR}/dataset.csv'\n\n\n# Create the directory\n!mkdir -p {PIPELINE_DIR}\n!mkdir -p {TRAINING_DATA_DIR}\n!mkdir -p {SERVING_MODEL_DIR}\n!mkdir -p {SERVING_DATA_DIR}\n","metadata":{"id":"TBJqC6-HfymZ","execution":{"iopub.status.busy":"2022-07-06T09:24:31.813346Z","iopub.execute_input":"2022-07-06T09:24:31.813788Z","iopub.status.idle":"2022-07-06T09:24:34.591896Z","shell.execute_reply.started":"2022-07-06T09:24:31.813732Z","shell.execute_reply":"2022-07-06T09:24:34.590484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pairs_df = pd.read_csv(INPUT_SOURCE_PAIRS_DATA)\npairs_df = pairs_df.replace(np.nan, '',regex=True)\npairs_df.shape","metadata":{"id":"I6MverMGJwg8","outputId":"20525ebd-ad9a-49ae-f554-0eeffd227531","execution":{"iopub.status.busy":"2022-07-06T09:24:34.595987Z","iopub.execute_input":"2022-07-06T09:24:34.59632Z","iopub.status.idle":"2022-07-06T09:24:43.124125Z","shell.execute_reply.started":"2022-07-06T09:24:34.596289Z","shell.execute_reply":"2022-07-06T09:24:43.12304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#combine address columns : address_1, city_1, state_1, zip_1 to full_address_1\npairs_df['full_address_1'] = pairs_df['address_1'].map(str) + \" \" + pairs_df['city_1'].map(str) + \" \" + pairs_df['state_1'].map(str) + \" \" + pairs_df['zip_1'].map(str) + \" Phone: \" + pairs_df['phone_1'].map(str)\npairs_df['full_address_2'] = pairs_df['address_2'].map(str) + \" \" + pairs_df['city_2'].map(str) + \" \" + pairs_df['state_2'].map(str) + \" \" + pairs_df['zip_2'].map(str) + \" Phone: \" + pairs_df['phone_2'].map(str)\npairs_df = pairs_df.drop(columns=['address_1','city_1','state_1','zip_1', 'phone_1', 'address_2','city_2','state_2','zip_2', 'phone_2'], axis=1)\npairs_df.dtypes","metadata":{"id":"27F98BrE1a9g","outputId":"31eb74d4-f484-487d-c6e4-a344c55c2c2a","execution":{"iopub.status.busy":"2022-07-06T09:24:43.128795Z","iopub.execute_input":"2022-07-06T09:24:43.131324Z","iopub.status.idle":"2022-07-06T09:24:46.260791Z","shell.execute_reply.started":"2022-07-06T09:24:43.131282Z","shell.execute_reply":"2022-07-06T09:24:46.259719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(INPUT_SOURCE_TRAIN_DATA)\ntrain_df = train_df.replace(np.nan, '',regex=True)","metadata":{"id":"PDnSMsXJsoVU","execution":{"iopub.status.busy":"2022-07-06T09:54:43.699759Z","iopub.execute_input":"2022-07-06T09:54:43.700454Z","iopub.status.idle":"2022-07-06T09:54:50.055962Z","shell.execute_reply.started":"2022-07-06T09:54:43.700419Z","shell.execute_reply":"2022-07-06T09:54:50.05479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create additional matching pairs from train.csv and add it to pairs dataframe\nadd_pairs_df = pd.merge(train_df, train_df, on=\"point_of_interest\", suffixes=('_1', '_2'))\nadd_pairs_df = add_pairs_df[add_pairs_df[\"id_1\"]!=add_pairs_df[\"id_2\"]]\nadd_pairs_df = add_pairs_df.drop([\"point_of_interest\"], axis=1)\nadd_pairs_df[\"match\"] = True\n\nadd_pairs_df['full_address_1'] = add_pairs_df['address_1'].map(str) + \" \" + add_pairs_df['city_1'].map(str) + \" \" + add_pairs_df['state_1'].map(str) + \" \" + add_pairs_df['zip_1'].map(str) + \" Phone: \" + add_pairs_df['phone_1'].map(str)\nadd_pairs_df['full_address_2'] = add_pairs_df['address_2'].map(str) + \" \" + add_pairs_df['city_2'].map(str) + \" \" + add_pairs_df['state_2'].map(str) + \" \" + add_pairs_df['zip_2'].map(str) + \" Phone: \" + add_pairs_df['phone_2'].map(str)\nadd_pairs_df = add_pairs_df.drop(columns=['address_1','city_1','state_1','zip_1', 'phone_1', 'address_2','city_2','state_2','zip_2', 'phone_2'], axis=1)\nadd_pairs_df.shape","metadata":{"id":"3DeX6VT8y7Wx","outputId":"909cdd4b-afdc-4a9a-9765-c33ee65ea4bd","execution":{"iopub.status.busy":"2022-07-06T09:54:54.766626Z","iopub.execute_input":"2022-07-06T09:54:54.768085Z","iopub.status.idle":"2022-07-06T09:55:15.457743Z","shell.execute_reply.started":"2022-07-06T09:54:54.768032Z","shell.execute_reply":"2022-07-06T09:55:15.456716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create additional non-matching pairs from train.csv and add it to pairs dataframe\n\nnon_match_df = train_df.head(1000)\nnon_match_df=non_match_df.merge(non_match_df, how='cross', suffixes=('_1', '_2'))\nnon_match_df = non_match_df[non_match_df['id_1'] != non_match_df['id_2']]\nnon_match_df.loc[non_match_df['point_of_interest_1'] != non_match_df['point_of_interest_2'], 'match'] = False\nnon_match_df.loc[non_match_df['point_of_interest_1'] == non_match_df['point_of_interest_2'], 'match'] = True\nnon_match_df = non_match_df.drop([\"point_of_interest_1\",\"point_of_interest_2\",], axis=1)\n\nnon_match_df['full_address_1'] = non_match_df['address_1'].map(str) + \" \" + non_match_df['city_1'].map(str) + \" \" + non_match_df['state_1'].map(str) + \" \" + non_match_df['zip_1'].map(str) + \" Phone: \" + non_match_df['phone_1'].map(str)\nnon_match_df['full_address_2'] = non_match_df['address_2'].map(str) + \" \" + non_match_df['city_2'].map(str) + \" \" + non_match_df['state_2'].map(str) + \" \" + non_match_df['zip_2'].map(str) + \" Phone: \" + non_match_df['phone_2'].map(str)\nnon_match_df = non_match_df.drop(columns=['address_1','city_1','state_1','zip_1', 'phone_1', 'address_2','city_2','state_2','zip_2', 'phone_2'], axis=1)\nnon_match_df.shape\n","metadata":{"id":"ExoVeY9v5R6y","outputId":"2fc83a12-2ecf-41d4-d9e6-4eca1d8c14dc","execution":{"iopub.status.busy":"2022-07-06T09:55:25.145179Z","iopub.execute_input":"2022-07-06T09:55:25.145538Z","iopub.status.idle":"2022-07-06T09:55:33.30871Z","shell.execute_reply.started":"2022-07-06T09:55:25.145508Z","shell.execute_reply":"2022-07-06T09:55:33.3077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pairs_df = pd.concat([pairs_df, add_pairs_df], ignore_index=True)\npairs_df = pd.concat([pairs_df, non_match_df], ignore_index=True)\npairs_df.shape","metadata":{"id":"a4khLZTT2jPF","outputId":"c06300e8-c0c4-4b40-cd09-e49efeecfb96","execution":{"iopub.status.busy":"2022-07-06T09:55:33.310658Z","iopub.execute_input":"2022-07-06T09:55:33.31096Z","iopub.status.idle":"2022-07-06T09:55:36.007852Z","shell.execute_reply.started":"2022-07-06T09:55:33.310934Z","shell.execute_reply":"2022-07-06T09:55:36.006732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pairs_df.drop_duplicates()\npairs_df.shape","metadata":{"id":"y72IQJKS1-4l","outputId":"ea45ee8a-afbf-46a0-fa85-1f4f6140b9a2","execution":{"iopub.status.busy":"2022-07-06T09:55:36.009673Z","iopub.execute_input":"2022-07-06T09:55:36.010121Z","iopub.status.idle":"2022-07-06T09:55:48.687757Z","shell.execute_reply.started":"2022-07-06T09:55:36.01007Z","shell.execute_reply":"2022-07-06T09:55:48.686689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pairs_df = pairs_df[pairs_df[\"id_1\"]!=pairs_df[\"id_2\"]]\npairs_df.shape","metadata":{"id":"tkm7IOwcjDby","outputId":"f9d6d2b0-963a-417d-bf9b-4ff25095d766","execution":{"iopub.status.busy":"2022-07-06T09:55:48.690732Z","iopub.execute_input":"2022-07-06T09:55:48.691137Z","iopub.status.idle":"2022-07-06T09:55:50.382527Z","shell.execute_reply.started":"2022-07-06T09:55:48.691096Z","shell.execute_reply":"2022-07-06T09:55:50.38149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pairs_df['match'] = pairs_df.match.astype(\"category\").cat.codes\ndisplay(pairs_df['match'].unique())\npairs_df.full_address_1 \npairs_df.shape","metadata":{"id":"yGMpKH_719a7","outputId":"92b29172-f0e5-492c-b14a-e8f2becea4d2","execution":{"iopub.status.busy":"2022-07-06T09:55:50.383887Z","iopub.execute_input":"2022-07-06T09:55:50.385054Z","iopub.status.idle":"2022-07-06T09:55:51.515957Z","shell.execute_reply.started":"2022-07-06T09:55:50.38501Z","shell.execute_reply":"2022-07-06T09:55:51.514924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pairs_df.head(2000).to_csv(TRAINING_DATA, index=False)\npairs_df.to_csv(TRAINING_DATA, index=False)","metadata":{"id":"0kiTvrJmWb1L","execution":{"iopub.status.busy":"2022-07-06T09:55:51.517253Z","iopub.execute_input":"2022-07-06T09:55:51.519013Z","iopub.status.idle":"2022-07-06T09:56:51.198624Z","shell.execute_reply.started":"2022-07-06T09:55:51.518973Z","shell.execute_reply":"2022-07-06T09:56:51.197476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del pairs_df\ndel add_pairs_df\n#del non_match_df","metadata":{"id":"5nQ_e5CSWijP","execution":{"iopub.status.busy":"2022-07-06T09:56:51.200323Z","iopub.execute_input":"2022-07-06T09:56:51.200681Z","iopub.status.idle":"2022-07-06T09:56:51.692528Z","shell.execute_reply.started":"2022-07-06T09:56:51.200645Z","shell.execute_reply":"2022-07-06T09:56:51.691536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name='3'></a>\n## 3 - Data Ingestion","metadata":{"id":"8HeAEQLAhg8I"}},{"cell_type":"markdown","source":"<a name='3-1'></a>\n### 3.1 - Setup the Interactive Context\n\nSetup the interactive context in pipeline directory","metadata":{"id":"ZES9v8ggpDv8"}},{"cell_type":"code","source":"# Declare the InteractiveContext and use a local sqlite file as the metadata store.\ncontext = InteractiveContext(pipeline_root=PIPELINE_DIR)","metadata":{"id":"8G-G-xLO3lkt","outputId":"89636d32-8e41-4e43-fcf6-33416231c8af","execution":{"iopub.status.busy":"2022-07-06T09:56:51.694207Z","iopub.execute_input":"2022-07-06T09:56:51.694589Z","iopub.status.idle":"2022-07-06T09:56:51.703235Z","shell.execute_reply.started":"2022-07-06T09:56:51.694545Z","shell.execute_reply":"2022-07-06T09:56:51.700117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name='3-2'></a>\n### 3.2 - Generating Examples\nIngest the data using TFX component - [ExampleGen](https://www.tensorflow.org/tfx/guide/examplegen)\n* The input is in CSV format so you will need to use the appropriate type of `ExampleGen` to handle it. \n* This function accepts a *directory* path to the training data and not the CSV file path itself. ","metadata":{"id":"Rzm9d4G0hynL"}},{"cell_type":"code","source":"# Instantiate ExampleGen with the input CSV dataset\nexample_gen = CsvExampleGen(input_base=TRAINING_DATA_DIR)\ncontext.run(example_gen)","metadata":{"id":"EL3CZQcg3lku","outputId":"7e8a1fa0-c891-4d76-cc02-71d0b83cc0ea","execution":{"iopub.status.busy":"2022-07-06T13:13:26.197391Z","iopub.execute_input":"2022-07-06T13:13:26.198529Z","iopub.status.idle":"2022-07-06T13:13:26.261039Z","shell.execute_reply.started":"2022-07-06T13:13:26.198491Z","shell.execute_reply":"2022-07-06T13:13:26.260171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name='4'></a>\n## 4 - Data Validation","metadata":{"id":"ZEtXqDzwsfm9"}},{"cell_type":"markdown","source":"<a name='4-1'></a>\n### 4.1 - StatisticsGen\n\nCompute the statistics using TFX Component - StatisticsGen. Visualizations provided by the integrated [FACETS](https://pair-code.github.io/facets/) library.","metadata":{"id":"zd3k6iIni-FE"}},{"cell_type":"code","source":"# Instantiate StatisticsGen with the ExampleGen ingested dataset\nstatistics_gen = StatisticsGen(examples=example_gen.outputs['examples'])\ncontext.run(statistics_gen)\n","metadata":{"id":"5u2EOMOm3lkw","outputId":"de439656-1fe4-457d-a301-aeaf112a217b","execution":{"iopub.status.idle":"2022-07-06T10:29:54.605787Z","shell.execute_reply.started":"2022-07-06T10:21:34.198394Z","shell.execute_reply":"2022-07-06T10:29:54.604752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the results\ncontext.show(statistics_gen.outputs['statistics'])","metadata":{"id":"exyb-VKD3lkw","execution":{"iopub.status.busy":"2022-07-06T10:29:54.607369Z","iopub.execute_input":"2022-07-06T10:29:54.608085Z","iopub.status.idle":"2022-07-06T10:29:54.748312Z","shell.execute_reply.started":"2022-07-06T10:29:54.608039Z","shell.execute_reply":"2022-07-06T10:29:54.747182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name='4-2'></a>\n### 4.2 - SchemaGen\n\nInfer the input dataset schema using TFX component SchemaGen to validate incoming datasets during training and serving. [SchemaGen](https://www.tensorflow.org/tfx/guide/schemagen) component.","metadata":{"id":"K6K2Wd9-tfdx"}},{"cell_type":"code","source":"# Instantiate SchemaGen with the output statistics from the StatisticsGen\nschema_gen = SchemaGen(statistics=statistics_gen.outputs['statistics'])\ncontext.run(schema_gen, enable_cache=True)","metadata":{"id":"_D9GZT1v3lkx","execution":{"iopub.status.busy":"2022-07-06T10:29:54.750042Z","iopub.execute_input":"2022-07-06T10:29:54.750417Z","iopub.status.idle":"2022-07-06T10:29:54.938089Z","shell.execute_reply.started":"2022-07-06T10:29:54.750381Z","shell.execute_reply":"2022-07-06T10:29:54.937179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the output\ncontext.show(schema_gen.outputs['schema'])","metadata":{"id":"lW6Vhxy-3lkx","execution":{"iopub.status.busy":"2022-07-06T10:29:54.939616Z","iopub.execute_input":"2022-07-06T10:29:54.939986Z","iopub.status.idle":"2022-07-06T10:29:54.976632Z","shell.execute_reply.started":"2022-07-06T10:29:54.939948Z","shell.execute_reply":"2022-07-06T10:29:54.97572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name='4-3'></a>\n### 4.3 - Schema Environments\n\nIn supervised learning, we train the model to make predictions by feeding a set of features with its corresponding label. Thus, our training dataset will have both the input features and label, and the schema is configured to detect these. ","metadata":{"id":"fHN_j-d5mCCZ"}},{"cell_type":"markdown","source":"<a name='5'></a>\n## 5 - Feature Engineering\n\n\n","metadata":{"id":"eNhFUd68nTYQ"}},{"cell_type":"markdown","source":"<a name='5-1'></a>\n### 5.1 - Transform\nUsing [TFX Transform component](https://www.tensorflow.org/tfx/api_docs/python/tfx/components/Transform) \n\n\n*   create constant module file\n*   create transform module file\n*   instantiate transform and run","metadata":{"id":"CbBVp2sCvRGK"}},{"cell_type":"code","source":"# Set the constants module filename\n_fs_constants_module_file = 'fs_constants.py'","metadata":{"id":"vz5VLpMF0R_s","execution":{"iopub.status.busy":"2022-07-06T10:29:54.97828Z","iopub.execute_input":"2022-07-06T10:29:54.978848Z","iopub.status.idle":"2022-07-06T10:29:54.983833Z","shell.execute_reply.started":"2022-07-06T10:29:54.978794Z","shell.execute_reply":"2022-07-06T10:29:54.982791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile {_fs_constants_module_file}\n\nSCALE_MINMAX_FEATURE_KEYS = [\n        \"name_distance\",\n        \"location_distance\"\n#        \"address_distance\",\n#        \"cityzip_distance\"\n#        \"url_distance\"\n#        \"phone_distance\"\n       ]\n\nVOCAB_FEATURE_KEYS = [\n\n        \"country_1\",\n        \"country_2\"\n #       \"categories_1\",\n #       \"categories_2\"\n        ]\n\nLABEL_KEY = \"match\"\n\n# Utility function for renaming the feature\ndef transformed_name(key):\n    return key + '_xf'","metadata":{"id":"FOkTSEia0UE3","execution":{"iopub.status.busy":"2022-07-06T10:29:54.98532Z","iopub.execute_input":"2022-07-06T10:29:54.986476Z","iopub.status.idle":"2022-07-06T10:29:54.994566Z","shell.execute_reply.started":"2022-07-06T10:29:54.986434Z","shell.execute_reply":"2022-07-06T10:29:54.993554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the transform module filename\n_fs_transform_module_file = 'fs_transform.py'","metadata":{"id":"Elp0jej91iiT","execution":{"iopub.status.busy":"2022-07-06T10:29:54.996171Z","iopub.execute_input":"2022-07-06T10:29:54.996563Z","iopub.status.idle":"2022-07-06T10:29:55.002601Z","shell.execute_reply.started":"2022-07-06T10:29:54.996522Z","shell.execute_reply":"2022-07-06T10:29:55.001405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile {_fs_transform_module_file}\n\nimport tensorflow_hub as hub\nimport tensorflow_text\nimport tensorflow as tf\nimport tensorflow_transform as tft\nimport numpy as np\nimport fs_constants\n\nembed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")\n\n_SCALE_MINMAX_FEATURE_KEYS = fs_constants.SCALE_MINMAX_FEATURE_KEYS\n_VOCAB_FEATURE_KEYS = fs_constants.VOCAB_FEATURE_KEYS\n_LABEL_KEY = fs_constants.LABEL_KEY\n_transformed_name = fs_constants.transformed_name\n\ndef text_similarity(text1,text2):\n    text1_vec = embed(tf.reshape(text1,[-1]))\n    text2_vec = embed(tf.reshape(text2,[-1]))\n    name_distance = tf.matmul(text1_vec, tf.transpose(text2_vec))\n    return name_distance[:,0]\n\ndef scale_longitude(lon):\n    return (lon + 78)/8.\n\ndef scale_latitude(lat):\n    return (lat - 37)/8.\n\ndef euclidean(lon1, lat1, lon2, lat2):\n    londiff = lon2 - lon1\n    latdiff = lat2 - lat1\n    return tf.sqrt(londiff*londiff + latdiff*latdiff)\n\ndef edit_distance(phone_1, phone_2):\n    return tf.edit_distance(phone_1, phone_2, normalize=True)\n\ndef poi_distance(lon1, lat1, lon2, lat2):\n    scaled_lon1 = scale_longitude(lon1)\n    scaled_lon2 = scale_longitude(lon2)\n    scaled_lat1 = scale_latitude(lat1)\n    scaled_lat2 = scale_latitude(lat2)\n    return euclidean(scaled_lon1, scaled_lat1, scaled_lon2, scaled_lat2)\n\ndef _fill_in_missing(x):\n    \"\"\"Replace missing values in a SparseTensor.\n   Fills in missing values of `x` with '' or 0, and converts to a dense tensor.\n    Args:\n      x: A `SparseTensor` of rank 2.  Its dense shape should have size at most 1\n       in the second dimension.\n    Returns:\n      A rank 1 tensor where missing values of `x` have been filled in.\n    \"\"\"\n    if not isinstance(x, tf.sparse.SparseTensor):\n        return x\n\n    default_value = '' if x.dtype == tf.string else 0\n    return tf.squeeze(\n        tf.sparse.to_dense(\n            tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1]),\n            default_value),\n        axis=1)\n\ndef preprocessing_fn(inputs):\n    features_dict = {}\n    \n    name_distance = text_similarity(inputs[\"name_1\"], inputs[\"name_2\"])\n    full_address_distance = text_similarity(_fill_in_missing(inputs[\"full_address_1\"]), _fill_in_missing(inputs[\"full_address_2\"]))\n    url_distance = text_similarity(_fill_in_missing(inputs[\"url_1\"]), _fill_in_missing(inputs[\"url_2\"]))\n    category_distance = text_similarity(_fill_in_missing(inputs[\"categories_1\"]), _fill_in_missing(inputs[\"categories_2\"]))\n    \n    location_distance = poi_distance(inputs[\"longitude_1\"],inputs[\"latitude_1\"], inputs[\"longitude_2\"],inputs[\"latitude_2\"])\n    \n    #for feature in _VOCAB_FEATURE_KEYS:\n    #    features_dict[_transformed_name(feature)] = tf.cast(\n    #                            tft.compute_and_apply_vocabulary(_fill_in_missing(inputs[feature])),dtype=tf.float32)                               \n                                    \n    features_dict[\"name_distance_xf\"] = name_distance\n    features_dict[\"full_address_distance_xf\"] = full_address_distance\n    features_dict[\"url_distance_xf\"] = url_distance\n    features_dict[\"category_distance_xf\"] = category_distance\n    features_dict[\"location_distance_xf\"] = location_distance\n        \n    \n    features_dict[\"name_distance_xf\"] = tft.scale_by_min_max(features_dict[\"name_distance_xf\"])\n    features_dict[\"full_address_distance_xf\"] = tft.scale_by_min_max(features_dict[\"full_address_distance_xf\"])\n    features_dict[\"url_distance_xf\"] = tft.scale_by_min_max(features_dict[\"url_distance_xf\"])\n    features_dict[\"category_distance_xf\"] = tft.scale_by_min_max(features_dict[\"category_distance_xf\"])\n    features_dict[\"location_distance_xf\"] = tft.scale_by_min_max(features_dict[\"location_distance_xf\"])\n        \n    features_dict[_LABEL_KEY] = tf.cast(inputs[_LABEL_KEY], tf.float32)\n    return features_dict\n","metadata":{"id":"PJpPxzh6kdNM","execution":{"iopub.status.busy":"2022-07-06T10:29:55.004422Z","iopub.execute_input":"2022-07-06T10:29:55.004916Z","iopub.status.idle":"2022-07-06T10:29:55.015234Z","shell.execute_reply.started":"2022-07-06T10:29:55.004733Z","shell.execute_reply":"2022-07-06T10:29:55.014222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantiate the Transform component\ntransform = Transform(examples=example_gen.outputs['examples'],\n                      schema=schema_gen.outputs['schema'],\n                      module_file=os.path.abspath(_fs_transform_module_file))\n# Run the component\ncontext.run(transform, enable_cache=True)","metadata":{"id":"dq88l0XjkdQI","execution":{"iopub.status.busy":"2022-07-06T10:29:55.016874Z","iopub.execute_input":"2022-07-06T10:29:55.017229Z","iopub.status.idle":"2022-07-06T12:31:58.968792Z","shell.execute_reply.started":"2022-07-06T10:29:55.017195Z","shell.execute_reply":"2022-07-06T12:31:58.967709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get URI and list subdirectories\ngraph_uri = transform.outputs['transform_graph'].get()[0].uri\nos.listdir(graph_uri)","metadata":{"id":"Z4P0VQwx2FnW","execution":{"iopub.status.busy":"2022-07-06T12:31:58.970348Z","iopub.execute_input":"2022-07-06T12:31:58.971262Z","iopub.status.idle":"2022-07-06T12:31:58.980074Z","shell.execute_reply.started":"2022-07-06T12:31:58.971223Z","shell.execute_reply":"2022-07-06T12:31:58.979106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name='6'></a>\n## 6 - Train Model\n\n\n","metadata":{"id":"2L_cHm97vtOo"}},{"cell_type":"markdown","source":"<a name='6-1'></a>\n#### 6.1 - Tuner Function\n\nUsing [TFX Tuner component](https://www.tensorflow.org/tfx/guide/tuner) \n\n*   create tuner module file\n*   instantiate tuner and run\n\n\n","metadata":{"id":"_t_0I9WsqkWO"}},{"cell_type":"code","source":"# Declare name of module file\n_tuner_module_file = 'tuner.py'","metadata":{"id":"2TCiMkYlITwb","execution":{"iopub.status.busy":"2022-07-06T12:31:58.981369Z","iopub.execute_input":"2022-07-06T12:31:58.982597Z","iopub.status.idle":"2022-07-06T12:31:58.986616Z","shell.execute_reply.started":"2022-07-06T12:31:58.98256Z","shell.execute_reply":"2022-07-06T12:31:58.98568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile {_tuner_module_file}\n\n# Define imports\nimport tensorflow as tf\nimport tensorflow_transform as tft\nfrom kerastuner.engine import base_tuner\nimport kerastuner as kt\nfrom tensorflow import keras\nfrom typing import NamedTuple, Dict, Text, Any, List\nfrom tfx.components.trainer.fn_args_utils import FnArgs, DataAccessor\n\n\n_FEATURE_KEYS = ['category_distance_xf', 'location_distance_xf', 'name_distance_xf',\n                 'full_address_distance_xf', 'url_distance_xf']\n\n# Declare namedtuple field names\nTunerFnResult = NamedTuple('TunerFnResult', [('tuner', base_tuner.BaseTuner),\n                                             ('fit_kwargs', Dict[Text, Any])])\n\n# Label key\nLABEL_KEY = 'match'\n\n# Callback for the search strategy\nstop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n\ndef _gzip_reader_fn(filenames):\n    return tf.data.TFRecordDataset(filenames, compression_type='GZIP')\n    \ndef _input_fn(file_pattern,\n              tf_transform_output,\n              num_epochs=None,\n              batch_size=32) -> tf.data.Dataset:\n    transformed_feature_spec = (\n        tf_transform_output.transformed_feature_spec().copy())\n\n    dataset = tf.data.experimental.make_batched_features_dataset(\n        file_pattern=file_pattern,\n        batch_size=batch_size,\n        features=transformed_feature_spec,\n        reader=_gzip_reader_fn,\n        num_epochs=num_epochs,\n        label_key=LABEL_KEY)\n    \n    return dataset\n\ndef model_builder(hp):\n \n    inputs = [\n      keras.layers.Input(shape=(1,), name=f)\n      for f in _FEATURE_KEYS\n        ]\n    \n    output = tf.keras.layers.concatenate(inputs)\n\n    hp_units1 = hp.Int('units1', min_value=32, max_value=512, step=32)\n    output = tf.keras.layers.Dense(units=hp_units1, activation='relu')(output)\n\n    hp_units2 = hp.Int('units2', min_value=32, max_value=512, step=32)\n    output = tf.keras.layers.Dense(units=hp_units2, activation='relu')(output)\n\n    hp_units3 = hp.Int('units3', min_value=32, max_value=512, step=32)\n    output = tf.keras.layers.Dense(units=hp_units3, activation='relu')(output)\n\n    hp_units4 = hp.Int('units4', min_value=32, max_value=512, step=32)\n    output = tf.keras.layers.Dense(units=hp_units4, activation='relu')(output)\n    \n    output = keras.layers.Dense(1, activation='sigmoid')(output)\n    model = tf.keras.Model(inputs=inputs, outputs=output)\n\n    # Tune the learning rate for the optimizer\n    # Choose an optimal value from 0.01, 0.001, or 0.0001\n    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n    \n    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n                loss='binary_crossentropy',\n                metrics=['accuracy'])\n    return model\n    \ndef tuner_fn(fn_args: FnArgs) -> TunerFnResult:\n    tuner = kt.Hyperband(model_builder,\n                     objective='val_accuracy',\n                     max_epochs=5,\n                     factor=3,\n                     directory=fn_args.working_dir,\n                     project_name='kt_hyperband')\n\n    tf_transform_output = tft.TFTransformOutput(fn_args.transform_graph_path)\n    train_set = _input_fn(fn_args.train_files[0], tf_transform_output)\n    val_set = _input_fn(fn_args.eval_files[0], tf_transform_output)\n    return TunerFnResult(\n        tuner=tuner,\n        fit_kwargs={ \n        \"callbacks\":[stop_early],\n        'x': train_set,\n        'validation_data': val_set,\n        'steps_per_epoch': fn_args.train_steps,\n        'validation_steps': fn_args.eval_steps\n            }\n        )","metadata":{"id":"K_8auMaGITwc","execution":{"iopub.status.busy":"2022-07-06T12:31:58.988161Z","iopub.execute_input":"2022-07-06T12:31:58.988759Z","iopub.status.idle":"2022-07-06T12:31:59.001689Z","shell.execute_reply.started":"2022-07-06T12:31:58.988707Z","shell.execute_reply":"2022-07-06T12:31:59.000559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setup the Tuner component\ntuner = Tuner(\n    module_file=os.path.abspath(_tuner_module_file),\n    examples=transform.outputs['transformed_examples'],\n    transform_graph=transform.outputs['transform_graph'],\n    train_args=trainer_pb2.TrainArgs(splits=['train'], num_steps=5000),\n    eval_args=trainer_pb2.EvalArgs(splits=['eval'], num_steps=5000)\n    )","metadata":{"id":"hrbgo4oXITwe","execution":{"iopub.status.busy":"2022-07-06T12:31:59.003186Z","iopub.execute_input":"2022-07-06T12:31:59.00377Z","iopub.status.idle":"2022-07-06T12:31:59.013292Z","shell.execute_reply.started":"2022-07-06T12:31:59.003714Z","shell.execute_reply":"2022-07-06T12:31:59.012311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"context.run(tuner, enable_cache=True)","metadata":{"id":"-hoR8JOKITwf","execution":{"iopub.status.busy":"2022-07-06T12:31:59.016089Z","iopub.execute_input":"2022-07-06T12:31:59.016774Z","iopub.status.idle":"2022-07-06T12:52:12.580764Z","shell.execute_reply.started":"2022-07-06T12:31:59.016726Z","shell.execute_reply":"2022-07-06T12:52:12.579764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name='6-2'></a>\n#### 6.2 - Trainer Function\n\nUsing [TFX Trainer component](https://www.tensorflow.org/tfx/guide/trainer) \n\n*   create trainer module file\n*   instantiate trainer and run\n\n\n","metadata":{"id":"KVDLF2yCwEzv"}},{"cell_type":"code","source":"# Declare trainer module file\n_fs_trainer_module_file = 'trainer.py'","metadata":{"id":"1eYhFVTwITwf","execution":{"iopub.status.busy":"2022-07-06T12:52:12.582488Z","iopub.execute_input":"2022-07-06T12:52:12.58287Z","iopub.status.idle":"2022-07-06T12:52:12.58785Z","shell.execute_reply.started":"2022-07-06T12:52:12.582829Z","shell.execute_reply":"2022-07-06T12:52:12.586767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile {_fs_trainer_module_file}\n\nfrom typing import Dict, List, Text\n\nimport os\nimport glob\nfrom absl import logging\n\nimport datetime\nimport tensorflow as tf\nimport tensorflow_transform as tft\n\nfrom tfx import v1 as tfx\nfrom tfx_bsl.public import tfxio\nfrom tensorflow_transform import TFTransformOutput\n\n_LABEL_KEY = 'match'\n_BATCH_SIZE = 32\n\ndef _input_fn(file_pattern: List[Text],\n              data_accessor: tfx.components.DataAccessor,\n              tf_transform_output: tft.TFTransformOutput,\n              batch_size: int = 64) -> tf.data.Dataset:\n\n    \"\"\"Generates features and label for tuning/training.\n\n    Args:\n      file_pattern: List of paths or patterns of input tfrecord files.\n      data_accessor: DataAccessor for converting input to RecordBatch.\n      tf_transform_output: A TFTransformOutput.\n      batch_size: representing the number of consecutive elements of returned\n        dataset to combine in a single batch\n\n    Returns:\n      A dataset that contains (features, indices) tuple where features is a\n        dictionary of Tensors, and indices is a single Tensor of label indices.\n    \"\"\"\n    return data_accessor.tf_dataset_factory(file_pattern, \n                                          tfxio.TensorFlowDatasetOptions(batch_size=batch_size, label_key=_LABEL_KEY),\n                                          tf_transform_output.transformed_metadata.schema)\n\ndef _get_tf_examples_serving_signature(model, tf_transform_output):\n    \"\"\"Returns a serving signature that accepts `tensorflow.Example`.\"\"\"\n  \n    model.tft_layer_inference = tf_transform_output.transform_features_layer()\n\n    @tf.function(input_signature=[tf.TensorSpec(shape=[None],\n                                                dtype=tf.string, name='examples')])\n    def serve_tf_examples_fn(serialized_tf_example):\n      \"\"\"Returns the output to be used in the serving signature.\"\"\"\n      raw_feature_spec = tf_transform_output.raw_feature_spec()\n      # Remove label feature since these will not be present at serving time.\n      raw_feature_spec.pop(_LABEL_KEY)\n      raw_features = tf.io.parse_example(serialized_tf_example, raw_feature_spec)\n      transformed_features = model.tft_layer_inference(raw_features)\n      logging.info('serve_transformed_features = %s', transformed_features)\n\n      outputs = model(transformed_features)\n      return {'outputs': outputs}\n\n    return serve_tf_examples_fn\n\ndef _get_transform_features_signature(model, tf_transform_output):\n    \"\"\"Returns a serving signature that applies tf.Transform to features.\"\"\"\n    model.tft_layer_eval = tf_transform_output.transform_features_layer()\n\n    @tf.function(input_signature=[\n        tf.TensorSpec(shape=[None], dtype=tf.string, name='examples')\n    ])\n    def transform_features_fn(serialized_tf_example):\n      \"\"\"Returns the transformed_features to be fed as input to evaluator.\"\"\"\n      raw_feature_spec = tf_transform_output.raw_feature_spec()\n      raw_features = tf.io.parse_example(serialized_tf_example, raw_feature_spec)\n      transformed_features = model.tft_layer_eval(raw_features)\n      logging.info('eval_transformed_features = %s', transformed_features)\n      return transformed_features\n\n    return transform_features_fn\n\ndef export_serving_model(tf_transform_output, model, output_dir):\n    \"\"\"Exports a keras model for serving.\n    Args:\n      tf_transform_output: Wrapper around output of tf.Transform.\n      model: A keras model to export for serving.\n      output_dir: A directory where the model will be exported to.\n    \"\"\"\n    # The layer has to be saved to the model for keras tracking purpases.\n    model.tft_layer = tf_transform_output.transform_features_layer()\n\n    signatures = {\n        'serving_default':\n            _get_tf_examples_serving_signature(model, tf_transform_output),\n        'transform_features':\n            _get_transform_features_signature(model, tf_transform_output),\n    }\n\n    model.save(output_dir, save_format='tf', signatures=signatures)\n\ndef _build_keras_model(tf_transform_output: TFTransformOutput,\n                       hp\n                       ) -> tf.keras.Model:\n    \"\"\"Creates a DNN Keras model for classifying taxi data.\n    Args:\n      tf_transform_output: [TFTransformOutput], the outputs from Transform\n    Returns:\n      A keras Model.\n    \"\"\"\n    feature_spec = tf_transform_output.transformed_feature_spec().copy()\n    feature_spec.pop(_LABEL_KEY)\n\n    inputs = {}\n    for key, spec in feature_spec.items():\n      if isinstance(spec, tf.io.VarLenFeature):\n        inputs[key] = tf.keras.layers.Input(\n            shape=[None], name=key, dtype=spec.dtype, sparse=True)\n      elif isinstance(spec, tf.io.FixedLenFeature):\n        inputs[key] = tf.keras.layers.Input(\n            shape=spec.shape or [1], name=key, dtype=spec.dtype)\n      else:\n        raise ValueError('Spec type is not supported: ', key, spec)\n\n    hp_units1 = hp.get('units1')\n    hp_units2 = hp.get('units2')\n    hp_units3 = hp.get('units3')\n    hp_units4 = hp.get('units4')\n    \n    output = tf.keras.layers.Concatenate()(tf.nest.flatten(inputs))\n    output = tf.keras.layers.Dense(units=hp_units1, activation='relu')(output)\n    output = tf.keras.layers.Dense(units=hp_units2, activation='relu')(output)\n    output = tf.keras.layers.Dense(units=hp_units3, activation='relu')(output)\n    output = tf.keras.layers.Dense(units=hp_units4, activation='relu')(output)\n    output = tf.keras.layers.Dense(1, activation='sigmoid')(output)\n\n    return tf.keras.Model(inputs=inputs, outputs=output)\n\ndef run_fn(fn_args: tfx.components.FnArgs):\n\n    tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n\n    train_dataset = _input_fn(fn_args.train_files, fn_args.data_accessor, \n                            tf_transform_output, _BATCH_SIZE)\n    eval_dataset = _input_fn(fn_args.eval_files, fn_args.data_accessor, \n                           tf_transform_output, _BATCH_SIZE)\n\n  # Load best hyperparameters\n    hp = fn_args.hyperparameters.get('values')\n    hp_learning_rate = hp.get('learning_rate')\n\n    model = _build_keras_model(tf_transform_output, hp)\n       \n    model.compile(\n        loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n        optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n        metrics=[tf.keras.metrics.BinaryAccuracy()])\n    \n    model.summary()\n\n  # Callback for TensorBoard\n    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n        log_dir=fn_args.model_run_dir, update_freq='batch')\n  \n    model.fit(\n       train_dataset,\n       epochs=10,\n       steps_per_epoch=fn_args.train_steps,\n       validation_data=eval_dataset,\n       validation_steps=fn_args.eval_steps,\n       callbacks=[tensorboard_callback])\n  \n   # Export the model.\n    export_serving_model(tf_transform_output, model, fn_args.serving_model_dir)","metadata":{"id":"I6XM25WnITwf","execution":{"iopub.status.busy":"2022-07-06T12:52:12.589409Z","iopub.execute_input":"2022-07-06T12:52:12.590002Z","iopub.status.idle":"2022-07-06T12:52:12.606627Z","shell.execute_reply.started":"2022-07-06T12:52:12.589967Z","shell.execute_reply":"2022-07-06T12:52:12.605566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setup the Trainer component\ntrainer = Trainer(\n    module_file=_fs_trainer_module_file,\n    examples=transform.outputs['transformed_examples'],\n    hyperparameters=tuner.outputs['best_hyperparameters'],\n    transform_graph=transform.outputs['transform_graph'],\n    schema=schema_gen.outputs['schema'],\n    train_args=tfx.proto.TrainArgs(num_steps=25000),\n    eval_args=tfx.proto.EvalArgs(num_steps=12000))","metadata":{"id":"XuFgE3nuD-oV","execution":{"iopub.status.busy":"2022-07-06T12:52:12.608192Z","iopub.execute_input":"2022-07-06T12:52:12.608862Z","iopub.status.idle":"2022-07-06T12:52:12.617903Z","shell.execute_reply.started":"2022-07-06T12:52:12.608783Z","shell.execute_reply":"2022-07-06T12:52:12.616875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run the component\ncontext.run(trainer, enable_cache=True)","metadata":{"id":"ggLqIJ1uITwg","execution":{"iopub.status.busy":"2022-07-06T12:52:12.619572Z","iopub.execute_input":"2022-07-06T12:52:12.620167Z","iopub.status.idle":"2022-07-06T13:12:58.096724Z","shell.execute_reply.started":"2022-07-06T12:52:12.620129Z","shell.execute_reply":"2022-07-06T13:12:58.0957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get artifact uri of trainer model output\nmodel_artifact_dir = trainer.outputs['model'].get()[0].uri\nprint(model_artifact_dir)\n\n# List subdirectories artifact uri\nprint(f'contents of model artifact directory:{os.listdir(model_artifact_dir)}')\n\n# Define the model directory\nmodel_dir = os.path.join(model_artifact_dir, 'Format-Serving')\n\n# List contents of model directory\nprint(f'contents of model directory: {os.listdir(model_dir)}')","metadata":{"id":"T6dQZNqUITwg","execution":{"iopub.status.busy":"2022-07-06T13:12:58.102131Z","iopub.execute_input":"2022-07-06T13:12:58.102433Z","iopub.status.idle":"2022-07-06T13:12:58.109279Z","shell.execute_reply.started":"2022-07-06T13:12:58.102405Z","shell.execute_reply":"2022-07-06T13:12:58.108259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_run_artifact_dir = trainer.outputs['model_run'].get()[0].uri\nprint(model_run_artifact_dir)\n%reload_ext tensorboard\n%tensorboard --logdir='./pipeline/Trainer/model_run/6'","metadata":{"id":"KZbi8rVmITwh","execution":{"iopub.status.busy":"2022-07-06T13:13:59.041307Z","iopub.execute_input":"2022-07-06T13:13:59.041718Z","iopub.status.idle":"2022-07-06T13:13:59.061713Z","shell.execute_reply.started":"2022-07-06T13:13:59.041683Z","shell.execute_reply":"2022-07-06T13:13:59.060789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r trainer.zip './pipeline/Trainer'","metadata":{"execution":{"iopub.status.busy":"2022-07-06T13:13:06.354366Z","iopub.execute_input":"2022-07-06T13:13:06.354792Z","iopub.status.idle":"2022-07-06T13:13:26.114541Z","shell.execute_reply.started":"2022-07-06T13:13:06.354729Z","shell.execute_reply":"2022-07-06T13:13:26.113346Z"},"trusted":true},"execution_count":null,"outputs":[]}]}